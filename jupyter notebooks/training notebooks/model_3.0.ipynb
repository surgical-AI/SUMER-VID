{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/model_1_outline.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change log\n",
    "### changing shuffle to False\n",
    "### changing sequence rate 5 -> 20\n",
    "\n",
    "## NEW IN THIS EXPERIMENT: trying RESNET 50\n",
    "## NEW IN THIS EXPERIMENT: Removing augmenting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequence generator shape (corrected) (b, n, w, h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1d2be527dc59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from patrice's blogpost\n",
    "from keras_video import VideoFrameGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = ['suture_throws', 'hand_ties', 'thread_cuts']\n",
    "classes.sort()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global params\n",
    "SIZE = (100, 100) # height and width of frame pxl by pxl\n",
    "CHANNELS = 3 # RGB or whatever\n",
    "NBFRAME = 5 # num frames in sequence \n",
    "BS = 8 # Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern to get videos and classes\n",
    "glob_pattern='../data_v3_model_2.2/model_data/{classname}/*.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data augmentation\n",
    "# data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "#     zoom_range=.1,\n",
    "#     horizontal_flip=True,\n",
    "#     rotation_range=8,\n",
    "#     width_shift_range=.2,\n",
    "#     height_shift_range=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create video frame generator\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    split_val=.33, \n",
    "    shuffle=False,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting validation data\n",
    "valid = train.get_validation_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras_video.utils\n",
    "# keras_video.utils.show_sample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD CONV NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, \\\n",
    "    MaxPool2D, GlobalMaxPool2D\n",
    "def build_mobilenet(shape=(224, 224, 3), nbout=3):\n",
    "#     model = keras.applications.mobilenet.MobileNet(\n",
    "#         include_top=False,\n",
    "#         input_shape=shape,\n",
    "#         weights='imagenet')\n",
    "    \n",
    "    model = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        #input_tensor=None,\n",
    "        input_shape=shape,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "    )\n",
    "    # Keep 9 layers to train﻿﻿\n",
    "    trainable = 9\n",
    "    for layer in model.layers[:-trainable]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[-trainable:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    # adding a max pool\n",
    "    output = GlobalMaxPool2D()\n",
    "\n",
    "    return keras.Sequential([model, output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0554aef9b42e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGRU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Shape (5, 112, 112, 3) 5 - time sequence length 112x112 = height vs width 3 - num channels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maction_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m112\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m112\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Create our convnet with (112, 112, 3) input shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mconvnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_mobilenet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
    "# Shape (5, 112, 112, 3) 5 - time sequence length 112x112 = height vs width 3 - num channels\n",
    "def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
    "    # Create our convnet with (112, 112, 3) input shape\n",
    "    convnet = build_mobilenet(shape[1:])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = keras.Sequential()\n",
    "    # add the convnet with (5, 112, 112, 3) shape\n",
    "    # KEY = allows you to add a time sequence to a layer one at a time\n",
    "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
    "    # here, you can also use GRU or LSTM\n",
    "    model.add(GRU(64))\n",
    "    # and finally, we make a decision network\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(nbout, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is where you tell the model how to train - loss function, weight update mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (20, 112, 112, 3)\n",
    "# action model - GRU set up for Time shifted CNN\n",
    "model = action_model(INSHAPE, len(classes))\n",
    "\n",
    "# this is where you tell the model how to train - loss function, weight update mechanism\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    'categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epochs, call backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "print('logs for this run are here: {}'.format(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=100\n",
    "# create a \"chkp\" directory before to run that\n",
    "# because ModelCheckpoint will write models inside\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'model2_3_1_chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        verbose=1),\n",
    "    tensorboard_callback\n",
    "]\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (non_gpu_tf)",
   "language": "python",
   "name": "non_gpu_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
