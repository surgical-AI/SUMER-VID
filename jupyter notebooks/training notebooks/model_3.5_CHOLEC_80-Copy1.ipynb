{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/model_1_outline.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change log\n",
    "### Epoch = 100\n",
    "### Shuffle=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequence generator shape (corrected) (b, n, w, h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from patrice's blogpost\n",
    "from keras_video import VideoFrameGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CalotTriangleDissection', 'CleaningCoagulation', 'ClippingCutting', 'GallbladderDissection', 'GallbladderPackaging', 'GallbladderRetraction', 'Preparation']\n"
     ]
    }
   ],
   "source": [
    "classes = ['CalotTriangleDissection',\n",
    " 'CleaningCoagulation',\n",
    " 'ClippingCutting',\n",
    " 'GallbladderDissection',\n",
    " 'GallbladderPackaging',\n",
    " 'GallbladderRetraction',\n",
    " 'Preparation']\n",
    "\n",
    "\n",
    "classes.sort()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some global params\n",
    "SIZE = (224, 224) # height and width of frame pxl by pxl\n",
    "CHANNELS = 3 # RGB or whatever\n",
    "NBFRAME = 5 # num frames in sequence \n",
    "BS = 8 # Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern to get videos and classes\n",
    "glob_pattern='../../cholec80/model_data_full/{classname}/*.avi'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data augmentation\n",
    "# data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "#     zoom_range=.1,\n",
    "#     horizontal_flip=True,\n",
    "#     rotation_range=8,\n",
    "#     width_shift_range=.2,\n",
    "#     height_shift_range=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class CalotTriangleDissection, validation count: 11743, train count: 23844\n",
      "class CleaningCoagulation, validation count: 2322, train count: 4717\n",
      "class ClippingCutting, validation count: 2191, train count: 4450\n",
      "class GallbladderDissection, validation count: 8319, train count: 16892\n",
      "class GallbladderPackaging, validation count: 1237, train count: 2514\n",
      "class GallbladderRetraction, validation count: 1074, train count: 2182\n",
      "class Preparation, validation count: 1397, train count: 2838\n",
      "Total data: 7 classes for 57437 files for train\n"
     ]
    }
   ],
   "source": [
    "# Create video frame generator\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    split_val=.33, \n",
    "    shuffle=False,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 7 classes for 28283 files for validation\n"
     ]
    }
   ],
   "source": [
    "# getting validation data\n",
    "valid = train.get_validation_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_video.utils\n",
    "#keras_video.utils.show_sample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid.files\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD CONV NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, \\\n",
    "    MaxPool2D, GlobalMaxPool2D\n",
    "#from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications import ResNet50 \n",
    "def build_mobilenet(shape=(224, 224, 3), nbout=3):\n",
    "#     model = MobileNet(\n",
    "#         include_top=False,\n",
    "#         input_shape=shape,\n",
    "#         weights='imagenet')\n",
    "#     # Keep 9 layers to train﻿﻿\n",
    "#     trainable = 9\n",
    "#     for layer in model.layers[:-trainable]:\n",
    "#         layer.trainable = False\n",
    "#     for layer in model.layers[-trainable:]:\n",
    "#         layer.trainable = True\n",
    "    model = ResNet50(include_top=True, weights='imagenet')\n",
    "    #return keras.Sequential([model])\n",
    "    return Model(inputs=model.input, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed, GRU, Dense, Dropout, LSTM\n",
    "from keras.initializers import GlorotNormal\n",
    "# Shape (5, 112, 112, 3) 5 - time sequence length 112x112 = height vs width 3 - num channels\n",
    "def action_model(shape=(5, 112, 112, 3), nbout=3):\n",
    "    # Create our convnet with (112, 112, 3) input shape\n",
    "    convnet = build_mobilenet(shape[1:])\n",
    "    \n",
    "    # then create our final model\n",
    "    model = keras.Sequential()\n",
    "    # add the convnet with (5, 112, 112, 3) shape\n",
    "    # KEY = allows you to add a time sequence to a layer one at a time\n",
    "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
    "    model.add(Dense(512))\n",
    "    # here, you can also use GRU or LSTM\n",
    "    #model.add(LSTM(512, kernel_initializer='glorot_normal', return_sequences=False, input_shape=(2048, 5)))\n",
    "    #model.add(LSTM(512, kernel_initializer='glorot_normal', return_sequences=False,  input_shape=(2048, 5, 8)))\n",
    "    model.add(LSTM(512, kernel_initializer='glorot_normal'))\n",
    "    # and finally, we make a decision network\n",
    "    model.add(Dense(nbout, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is where you tell the model how to train - loss function, weight update mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 128, 128, 3)\n",
    "print(INSHAPE)\n",
    "# action model - GRU set up for Time shifted CNN\n",
    "model = action_model(INSHAPE, len(classes))\n",
    "\n",
    "#this is where you tell the model how to train - loss function, weight update mechanism\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "model.compile(\n",
    "    optimizer,\n",
    "    'categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epochs, call backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs for this run are here: logs/fit/20210621-231113\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "print('logs for this run are here: {}'.format(log_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7179/7179 [==============================] - ETA: 0s - loss: 10.5344 - acc: 0.2966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video ../../cholec80/model_data_full/GallbladderDissection\\GallbladderDissection24977.avi, 0 total, 0 extracted\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 23.0 MiB for an array with shape (8, 5, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\keras_video\\generator.py\", line 364, in __getitem__\n    return np.array(images), np.array(labels)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 23.0 MiB for an array with shape (8, 5, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 23.0 MiB for an array with shape (8, 5, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\keras_video\\generator.py\", line 364, in __getitem__\n    return np.array(images), np.array(labels)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 23.0 MiB for an array with shape (8, 5, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_39262]\n\nFunction call stack:\ntest_function -> test_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3c4a1613e105>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"logs/fit/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1131\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  MemoryError: Unable to allocate 23.0 MiB for an array with shape (8, 5, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\keras_video\\generator.py\", line 364, in __getitem__\n    return np.array(images), np.array(labels)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 23.0 MiB for an array with shape (8, 5, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  MemoryError: Unable to allocate 23.0 MiB for an array with shape (8, 5, 224, 224, 3) and data type float32\nTraceback (most recent call last):\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\calvinap\\miniconda3\\envs\\hopethisworks3\\lib\\site-packages\\keras_video\\generator.py\", line 364, in __getitem__\n    return np.array(images), np.array(labels)\n\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 23.0 MiB for an array with shape (8, 5, 224, 224, 3) and data type float32\n\n\n\t [[{{node PyFunc}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[IteratorGetNext/_2]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_test_function_39262]\n\nFunction call stack:\ntest_function -> test_function\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# create a \"chkp\" directory before to run that\n",
    "# because ModelCheckpoint will write models inside\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'model2_3_1_chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "        verbose=1),\n",
    "    tensorboard_callback\n",
    "]\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8(htw3)",
   "language": "python",
   "name": "hopethisworks3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
